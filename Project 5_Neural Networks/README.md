In this project, I set out to evaluate whether a simple handwriting test could help identify young students who may need additional support developing their motor skills. Using a dataset of 42,000 handwritten digits, I built and compared two models—a K-Nearest Neighbors (KNN) classifier and a neural network—following the module’s objective of understanding when and how neural networks outperform more traditional algorithms. I began by exploring and preparing the dataset, standardizing pixel-intensity features, examining class distributions, and verifying data quality before splitting the data into training and testing sets.

I first implemented a KNN classifier, which achieved an accuracy of about 64%, revealing significant limitations in handling this high-dimensional image data. I then built a neural network using an MLPClassifier with tuned parameters, which improved the accuracy to nearly 70% and showed stronger performance across most digit classes. After benchmarking both models using accuracy, F1-scores, and confusion matrices, I determined that the neural network—despite its imperfect accuracy—was the more effective and scalable approach for handwriting recognition tasks. My findings suggest that with further tuning, enhanced preprocessing, or feature engineering, neural networks could provide meaningful support in detecting students who may benefit from early motor-skill intervention.
